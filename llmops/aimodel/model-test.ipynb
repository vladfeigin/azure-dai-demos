{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "import os\n",
    "client = AzureOpenAI(api_key=os.getenv(\"AZURE_OPENAI_KEY\"), \n",
    "                     api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"), \n",
    "                     azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "                     azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"************\")\n",
    "\n",
    "api_key=os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "print(f\"************api_key= {api_key}\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>groundeness</th>\n",
       "      <th>relevance</th>\n",
       "      <th>similarity</th>\n",
       "      <th>coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write a haiku about recursion in programming.</td>\n",
       "      <td>Recursion in code, a loop that repeats itself,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        question  \\\n",
       "0  Write a haiku about recursion in programming.   \n",
       "\n",
       "                                        ground_truth context response  \\\n",
       "0  Recursion in code, a loop that repeats itself,...     NaN      NaN   \n",
       "\n",
       "  groundeness relevance similarity coherence  \n",
       "0         NaN       NaN        NaN       NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "eval_res = pd.DataFrame(columns=[\"question\", \"ground_truth\", \"context\", \"response\", \"groundeness\", \"relevance\", \"similarity\", \"coherence\"])\n",
    "row = pd.DataFrame([{\"question\": \"Write a haiku about recursion in programming.\", \"ground_truth\": \"Recursion in code, a loop that repeats itself, until it doesn't.\"}])   \n",
    "pd.concat([eval_res, row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groundeness': 0.5, 'relevance': 0.4}\n",
      "[{'question': 'Write a haiku about recursion in programming.', 'ground_truth': \"Recursion in code, a loop that repeats itself, until it doesn't.\", 'context': 'You are a helpful assistant.', 'response': \"Recursion in code, a loop that repeats itself, until it doesn't.\", 'groundeness': 0.5, 'relevance': 0.4}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eval_res = pd.DataFrame(columns=[\"question\", \"ground_truth\", \"context\", \"response\"])\n",
    "\n",
    "eval_res[\"question\"] = [\"Write a haiku about recursion in programming.\"]\n",
    "eval_res[\"ground_truth\"] = [\"Recursion in code, a loop that repeats itself, until it doesn't.\"]\n",
    "eval_res[\"context\"] = [\"You are a helpful assistant.\"]\n",
    "eval_res[\"response\"] = [\"Recursion in code, a loop that repeats itself, until it doesn't.\"]\n",
    "\n",
    "eval_res_scores = pd.DataFrame(columns=[\"question\", \"ground_truth\", \"context\", \"response\"])\n",
    "\n",
    "\n",
    "def groundeness(x):\n",
    "    return 0.5\n",
    "def relevance(x):\n",
    "    return 0.4\n",
    "\n",
    "evaluators = {\"groundeness\": groundeness, \"relevance\": relevance}\n",
    "scores = {}\n",
    "\n",
    "for index, row in eval_res.iterrows():\n",
    "    \n",
    "    new_row = row.to_dict()\n",
    "    \n",
    "    for name, func in evaluators.items():\n",
    "        new_row[name] = func(row)\n",
    "        if name not in scores:\n",
    "            scores[name] = new_row[name]\n",
    "        else:\n",
    "            scores[name] += new_row[name]\n",
    "\n",
    "    eval_res_scores = pd.concat([eval_res_scores, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "eval_res_scores.head()\n",
    "print(scores)\n",
    "\n",
    "d = eval_res_scores.to_dict(orient=\"records\")\n",
    "print(d) \n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "#add code which add a new score to the scores dictionary. The key like relevancy could new (when we create it a first time)\n",
    "#check if a keys exists in a dictionary if yes , just expand the list with a new value otherwise create a new key with a value \n",
    "\n",
    "def add_score(scores, key, value):\n",
    "    if key in scores:\n",
    "        scores[key].extend([value])\n",
    "    else:\n",
    "        scores[key] = [value]\n",
    "        \n",
    "add_score(scores, \"relevancy\", 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relevancy': [0.5]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_score(scores, \"relevancy\", 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relevancy': [0.5, 0.1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'azure_endpoint': 'https://openai-australia-east-303474.openai.azure.com/openai/deployments/gpt-4o-3/chat/completions?api-version=2024-08-01-preview', 'api_key': '92ab6cf3f727424aad3e5b8b1ae55030', 'azure_deployment': 'gpt-4o-3', 'api_version': '2024-08-01-preview'}\n"
     ]
    }
   ],
   "source": [
    "model_config = {\n",
    "    \"azure_endpoint\": os.getenv(\"AZURE_OPENAI_EVALUATION_ENDPOINT\"),\n",
    "    \"api_key\": os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    \"azure_deployment\": os.getenv(\"AZURE_OPENAI_EVALUATION_DEPLOYMENT\"),\n",
    "    \"api_version\": os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "}\n",
    "\n",
    "print (model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import (\n",
    "    RelevanceEvaluator,\n",
    "    GroundednessEvaluator,\n",
    "    SimilarityEvaluator,\n",
    "    CoherenceEvaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundeness = GroundednessEvaluator(model_config)\n",
    "\n",
    "response=groundeness( response=\"Microsoft Fabric is an all-in-one analytics solution for enterprises. It provides built-in enterprise-grade governance and compliance capabilities, powered by Microsoft Purview. Fabric allows users to bring their existing Azure Data Factory to their Fabric workspace, and it supports various certifications such as HIPAA, ISO 27017, ISO 27018, ISO 27001, and ISO 27701. For more information on the latest features and updates, you can follow the Microsoft Fabric Updates Blog and the Microsoft Fabric Blog\",\n",
    "        context=\"Microsoft Fabric is an end-to-end analytics and data platform designed for enterprises that require a unified solution. It encompasses data movement, processing, ingestion, transformation, real-time event routing, and report building. It offers a comprehensive suite of services including Data Engineering, Data Factory, Data Science, Real-Time Analytics, Data Warehouse, and Databases. With Fabric, you don't need to assemble different services from multiple vendors. Instead, it offers a seamlessly integrated, user-friendly platform that simplifies your analytics requirements. Operating on a Software as a Service (SaaS) model, Fabric brings simplicity and integration to your solutions.\")[\"gpt_groundedness\"]\n",
    "\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AgentConfiguration': {'revision': 1.0, 'agent_name': 'rag_agent', 'model_name': 'gpt-4o', 'model_version': '2024-05-13', 'model_deployment': 'gpt-4o-2', 'model_deployment_endpoint': 'https://openai-australia-east-303474.openai.azure.com/openai/deployments/gpt-4o-2/chat/completions?api-version=2024-08-01-preview', 'openai_api_version': '2024-08-01-preview', 'retrieval': {'search_type': 'semantic_hybrid', 'top_k': 5}, 'model_parameters': {'temperature': 0.0, 'seed': 42}, 'intent_system_prompt': 'Your goal is to retrieve a user intent. Given a chat history and the latest user question,  which might reference context in the chat history, formulate a standalone question which can be understood without the chat history.   Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\\n', 'chat_system_prompt': 'You are helpful assistant, helping the use nswer questions about Microsoft technologies.  You answer questions about Azure, Microsoft 365, Dynamics 365, Power Platform, Azure, Microsoft Fabric and other Microsoft technologies  Do not use your internal knowledge, but only provided context in the prompt.  Do not answer not related to Microsoft technologies questions.  Provide the best answer based on the context in concise and clear manner.  Find the main points in a question and emphasize them in the answer.  If the provided context is not enough to answer the question, ask for more information.\\n    \\n<context> {context} </context>\"\\n', 'human_template': 'question: {input}'}}\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import configure_tracing, get_credential, configure_logging, load_agent_configuration\n",
    "\n",
    "rag_config = load_agent_configuration(\"../rag/rag_agent_config.yaml\")\n",
    "\n",
    "print(rag_config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'revision': 1.0,\n",
       " 'agent_name': 'rag_agent',\n",
       " 'model_name': 'gpt-4o',\n",
       " 'model_version': '2024-05-13',\n",
       " 'model_deployment': 'gpt-4o-2',\n",
       " 'model_deployment_endpoint': 'https://openai-australia-east-303474.openai.azure.com/openai/deployments/gpt-4o-2/chat/completions?api-version=2024-08-01-preview',\n",
       " 'openai_api_version': '2024-08-01-preview',\n",
       " 'retrieval': {'search_type': 'semantic_hybrid', 'top_k': 5},\n",
       " 'model_parameters': {'temperature': 0.0, 'seed': 42},\n",
       " 'intent_system_prompt': 'Your goal is to retrieve a user intent. Given a chat history and the latest user question,  which might reference context in the chat history, formulate a standalone question which can be understood without the chat history.   Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\\n',\n",
       " 'chat_system_prompt': 'You are helpful assistant, helping the use nswer questions about Microsoft technologies.  You answer questions about Azure, Microsoft 365, Dynamics 365, Power Platform, Azure, Microsoft Fabric and other Microsoft technologies  Do not use your internal knowledge, but only provided context in the prompt.  Do not answer not related to Microsoft technologies questions.  Provide the best answer based on the context in concise and clear manner.  Find the main points in a question and emphasize them in the answer.  If the provided context is not enough to answer the question, ask for more information.\\n    \\n<context> {context} </context>\"\\n',\n",
       " 'human_template': 'question: {input}'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (type(rag_config))\n",
    "rag_config[\"AgentConfiguration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "gpt-4o\n",
      "2024-05-13\n",
      "gpt-4o-2\n",
      "https://openai-australia-east-303474.openai.azure.com/openai/deployments/gpt-4o-2/chat/completions?api-version=2024-08-01-preview\n",
      "semantic_hybrid\n",
      "5\n",
      "0.0\n",
      "42\n",
      "Your goal is to retrieve a user intent. Given a chat history and the latest user question,  which might reference context in the chat history, formulate a standalone question which can be understood without the chat history.   Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (rag_config[\"AgentConfiguration\"][\"revision\"])\n",
    "print (rag_config[\"AgentConfiguration\"][\"model_name\"])\n",
    "print (rag_config[\"AgentConfiguration\"][\"model_version\"])\n",
    "print (rag_config[\"AgentConfiguration\"][\"model_deployment\"])\n",
    "print (rag_config[\"AgentConfiguration\"][\"model_deployment_endpoint\"])\n",
    "print (rag_config[\"AgentConfiguration\"][\"retrieval\"][\"search_type\"])\n",
    "print (rag_config[\"AgentConfiguration\"][\"retrieval\"][\"top_k\"])\n",
    "print (rag_config[\"AgentConfiguration\"][\"model_parameters\"][\"temperature\"])\n",
    "print (rag_config[\"AgentConfiguration\"][\"model_parameters\"][\"seed\"])\n",
    "print (rag_config[\"AgentConfiguration\"][\"intent_system_prompt\"])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
